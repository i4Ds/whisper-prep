# Output structure: out_folder_base/dataset_name/split_name
dataset_name: stt4sg-train_all # Name of the dataset (e.g. STT or SDS). This will be the main output folder.
split_name: train # Name of the data split (e.g. Train, Test, Validation).
out_folder_base: /mnt/nas05/data01/vincenzo/sg_data/train-all  # Base path for all output

# Data Sources
tsv_paths: ["/mnt/nas05/data01/vincenzo/stt4sg_data/stt4sg-350_v2.1/train_all.tsv"]
clips_folders: ["/mnt/nas05/data01/vincenzo/stt4sg_data/stt4sg-350_v2.1/clips"]
partials: [1.0] # Proportion of each dataset to use (e.g. 0.5 will use 50% of the dataset)

# Generation configuration
maintain_speaker_chance: 0.5 # Probability of keeping the same speaker for consecutive utterances
n_samples_per_srt: 120 # Number of audio samples to combine into each SRT file

# Overlap settings
overlap_chance: 0.8 # Probability of creating an overlap between consecutive audio clips
                    # Overlap occurs only in non-speech segments, as detected by Voice Activity Detection (VAD)

max_overlap_chance: 0.5 # Probability of maximum overlap when an overlap occurs
                        # If triggered, non-speech audio is removed, resulting in back-to-back speech
                        # If not triggered, a random amount of non-speech audio is kept between utterances
                        # It can only trigger if overlap_chance was triggered
max_overlap_duration: 0.2  # Max duration of the overlap in seconds. So if there is an overlap triggered, then the overlap will be between 0 and max_overlap_duration, thus having two speech overlap.

# Settings
filter_french: true # Whether to filter out French audio files
netflix_normalize: true # Whether to apply Netflix normalization rules to SRT files
normalize_text: true # Whether to normalize text in the dataset

# Upload to HuggingFace
upload_to_hu: true # Whether to upload the dataset to HuggingFace
hu_private: true
hu_repo: i4ds/stt4sg-train-all # HuggingFace repository identifier